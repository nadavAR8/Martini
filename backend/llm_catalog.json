{
    "models": [
        {
            "model_name": "LLaMA-3-8B",
            "stars_ranking": 4.5,
            "number_of_ratings": 30000,
            "categories": [
                "coding & programming"
            ],
            "bayesian_score": 4.4308
        },
        {
            "model_name": "DeepSeek-Coder-33B",
            "stars_ranking": 5.0,
            "number_of_ratings": 25000,
            "categories": [
                "coding & programming"
            ],
            "bayesian_score": 4.7781
        },
        {
            "model_name": "CodeLlama-34B-Instruct",
            "stars_ranking": 4.0,
            "number_of_ratings": 18000,
            "categories": [
                "coding & programming"
            ],
            "bayesian_score": 4.0797
        },
        {
            "model_name": "Phind-CodeLlama",
            "stars_ranking": 4.5,
            "number_of_ratings": 22000,
            "categories": [
                "coding & programming"
            ],
            "bayesian_score": 4.4135
        },
        {
            "model_name": "Replit-Code-v1.5",
            "stars_ranking": 3.5,
            "number_of_ratings": 9000,
            "categories": [
                "coding & programming"
            ],
            "bayesian_score": 3.8806
        },
        {
            "model_name": "Galactica-30B",
            "stars_ranking": 4.0,
            "number_of_ratings": 15000,
            "categories": [
                "physics"
            ],
            "bayesian_score": 4.0893
        },
        {
            "model_name": "SciPhi-Mistral-7B",
            "stars_ranking": 4.5,
            "number_of_ratings": 12000,
            "categories": [
                "physics"
            ],
            "bayesian_score": 4.3742
        },
        {
            "model_name": "PhysLLM-7B",
            "stars_ranking": 3.0,
            "number_of_ratings": 8000,
            "categories": [
                "physics"
            ],
            "bayesian_score": 3.6796
        },
        {
            "model_name": "LLaMA-Physics-Tuned",
            "stars_ranking": 4.5,
            "number_of_ratings": 20000,
            "categories": [
                "physics"
            ],
            "bayesian_score": 4.4077
        },
        {
            "model_name": "OpenHermes-2.5-Physics",
            "stars_ranking": 4.0,
            "number_of_ratings": 11000,
            "categories": [
                "physics"
            ],
            "bayesian_score": 4.1063
        },
        {
            "model_name": "MedAlpaca-13B",
            "stars_ranking": 4.5,
            "number_of_ratings": 17000,
            "categories": [
                "medical & health"
            ],
            "bayesian_score": 4.3975
        },
        {
            "model_name": "PMC-LLaMA",
            "stars_ranking": 4.0,
            "number_of_ratings": 15500,
            "categories": [
                "medical & health"
            ],
            "bayesian_score": 4.0875
        },
        {
            "model_name": "ClinicalCamel-2",
            "stars_ranking": 3.5,
            "number_of_ratings": 10000,
            "categories": [
                "medical & health"
            ],
            "bayesian_score": 3.8616
        },
        {
            "model_name": "GatorTron-OG",
            "stars_ranking": 3.0,
            "number_of_ratings": 7000,
            "categories": [
                "medical & health"
            ],
            "bayesian_score": 3.7195
        },
        {
            "model_name": "BioMistral-7B",
            "stars_ranking": 4.0,
            "number_of_ratings": 9000,
            "categories": [
                "medical & health"
            ],
            "bayesian_score": 4.1175
        }
    ],
    "global_stats": {
        "total_ratings": 228500,
        "global_avg_rating": 4.2232
    }
}